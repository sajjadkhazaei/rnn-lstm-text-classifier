{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bad5cc8",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b6edced5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets transformers --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f7acc40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_dataset\n",
    "from transformers import BertTokenizerFast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5bd8a6",
   "metadata": {},
   "source": [
    "# Check device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "32fc31db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"Device:\", device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76f128f",
   "metadata": {},
   "source": [
    "# Load AG News Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4092a06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"ag_news\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b6b8f68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = dataset['train']\n",
    "test_set = dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "864f8e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 120000, Test size: 7600\n",
      "Example: {'text': \"Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\\\band of ultra-cynics, are seeing green again.\", 'label': 2}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train size: {len(train_set)}, Test size: {len(test_set)}\")\n",
    "print(\"Example:\", train_set[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f8255cd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120000, 2)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b79fc808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['text', 'label']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.column_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8888ad41",
   "metadata": {},
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f28e144d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3f42cf",
   "metadata": {},
   "source": [
    "# Tokenization + Padding + Truncation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d1efdebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(batch):\n",
    "    return tokenizer(\n",
    "        batch['text'],\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=20\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affbed65",
   "metadata": {},
   "source": [
    "## Map_style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "de0f1d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_set.map(tokenize, batched=True)\n",
    "test_dataset = test_set.map(tokenize, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d38514",
   "metadata": {},
   "source": [
    "\n",
    "# Set Format for PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7dc62cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "test_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec92802a",
   "metadata": {},
   "source": [
    "# DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f68be9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9836f608",
   "metadata": {},
   "source": [
    "# Check a batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6d3a3d0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': tensor([1, 0, 0, 0, 3, 2, 0, 2, 0, 2, 1, 1, 1, 2, 2, 0, 1, 1, 3, 1, 0, 1, 0, 2,\n",
       "         2, 1, 0, 0, 0, 2, 1, 0]),\n",
       " 'input_ids': tensor([[  101, 12281,  2534,  6160,  2015,  3123,  1999, 10637,  2069,  3198,\n",
       "           2151,  3598,  5470,  2000,  2862,  1996,  4602,  2867,  1999,   102],\n",
       "         [  101,  2859,  1005,  1055,  2280,  2343, 20613,  4332,  2058,  2197,\n",
       "           2695,  2000, 15876,  1006,  3010,  2811,  1007,  3010,  2811,   102],\n",
       "         [  101,  4922,  5222,  2491,  2058,  4001,  2000, 21245,  6218,  2006,\n",
       "           2373,  2660,  1001,  4464,  1025,  1055,  3539,  2704,  1010,   102],\n",
       "         [  101, 22129,  3003,  2018,  3449, 13936,  3956,  2005,  2086,  1006,\n",
       "           9706,  1007,  9706,  1011,  4748,  7229,  2632,  1011,  1043,   102],\n",
       "         [  101, 18106,  8039,  2188,  2678,  9260, 25975,  5815,  2000,  2049,\n",
       "          14927,  2005,  3617, 12126,  1998,  2678, 17792,  5130,  1010,   102],\n",
       "         [  101,  1057,  5910, 23311,  2849,  1997, 10396, 25818,  2099,  1057,\n",
       "           5910,  2506,  2000, 11740,  2039,  2797,  8169,  7045,  7483,   102],\n",
       "         [  101, 15768,  7358,  2004,  3514,  2379,  2015,  1032,  1002,  2753,\n",
       "           1037,  8460,  2047,  2259,  1011,  3514,  7597,  2584,  1037,   102],\n",
       "         [  101, 17264, 12235,  3111,  2039,  1014,  1012,  1023,  7473,  2102,\n",
       "           1999, 15476,  2899,  1006, 26665,  1007,  1011, 12235,  3111,   102],\n",
       "         [  101,  2329,  6926, 21801,  2006,  1057,  1012,  1055,  1012, 10130,\n",
       "           5571,  1037,  2158,  4727,  1999,  3725,  1999,  2257,  2005,   102],\n",
       "         [  101,  7922,  8908,  7233,  2005,  3416,  5219,  2414,  1006, 26665,\n",
       "           1007,  1011,  1996,  7922, 13949,  2114,  2350, 12731, 14343,   102],\n",
       "         [  101,  7850,  2006,  7493,  2240,  1996,  5088,  7850,  3005,  3105,\n",
       "           3036,  2003,  2104,  1996,  2087,  6387, 17423,  2122,  2420,   102],\n",
       "         [  101,  4542,  4978,  3805,  1997,  4940,  2452,  4542,  1998,  2844,\n",
       "           7266,  1999,  1996,  2827,  2103,  1997,  4940,  2003,  3517,   102],\n",
       "         [  101, 13433, 16671,  5420,  4324,  1996,  3481,  2044,  4055,  6586,\n",
       "          12803,  9168,  2015, 15944,  1010,  4320,  2007,  1996,  9824,   102],\n",
       "         [  101, 15505,  9739, 19428,  1997,  3119, 15074,  3891,  1006,  9706,\n",
       "           1007,  9706,  1011, 13408,  3119, 15074,  2015,  2776,  2071,   102],\n",
       "         [  101,  4341,  2393,  4867,  3279,  2005,  2061, 10760,  3762,  1005,\n",
       "           1055,  1006, 26665,  1007, 26665,  1011,  2248, 10470, 22862,   102],\n",
       "         [  101,  5611,  5268,  1010,  2176, 17671,  2730,  1999, 14474, 14474,\n",
       "           2103,  1010, 14474,  6167,  1024, 22129, 17671,  2730,  2019,   102],\n",
       "         [  101,  4920,  1999,  2028,  1029, 27905,  1011,  1011,  2004, 14198,\n",
       "          20601,  2015,  4607,  1996,  2345,  6241,  1997,  1996, 17714,   102],\n",
       "         [  101,  4010,  3110,  2013,  4524,  9050,  2047,  2259,  1011,  1011,\n",
       "           1996, 22035,  2102,  1025, 14040,  6243,  1010, 22035,  2102,   102],\n",
       "         [  101,  3103, 12702, 29390,  9372,  2041,  2172,  1011, 19605,  5943,\n",
       "           2483,  2184,  3103, 12702, 29390,  4297,  1012,  1006,  3103,   102],\n",
       "         [  101,  2339, 12669,  2080,  2018,  2000,  2175,  5639, 12669,  3385,\n",
       "           8655,  2370,  2046,  2028, 26668,  4920,  2011, 13856,  2010,   102],\n",
       "         [  101,  5747, 28667, 11390,  1010,  2758,  7404,  2162,  2097,  2022,\n",
       "           2180,  8423,  1010,  2702,  2078,  1012,  1011,  2343,  5747,   102],\n",
       "         [  101,  4715,  1024,  2061, 26639,  2015,  2064,  3288,  2204,  2335,\n",
       "           2000,  8142,  1010,  2758, 18330,  2121,  2414,  1024,  8142,   102],\n",
       "         [  101,  9003,  3559,  2179,  5905,  1999, 26201,  2553, 14426,  1010,\n",
       "           6239,  1011,  1011,  1037,  2457,  7331, 13657,  2932,  3559,   102],\n",
       "         [  101, 24547,  1011, 20481,  7906,  2168,  1011,  3573,  4341, 17680,\n",
       "           1006, 26665,  1007, 26665,  1011, 24547,  1011, 20481,  5324,   102],\n",
       "         [  101,  5470,  8034, 11530,  6661,  2991,  2006,  9529, 24185,  2229,\n",
       "           1006, 26665,  1007, 26665,  1011,  6661,  1997,  1057,  1012,   102],\n",
       "         [  101,  2724,  1997,  1996,  2154,  1011,  1011,  2308,  1001,  4464,\n",
       "           1025,  1055,  3509,  7454,  2339,  2017,  2323,  3422,  1024,   102],\n",
       "         [  101,  1017, 21329,  5152, 17671,  6878,  1999, 14426,  2886, 14766,\n",
       "           2056,  5958,  2008,  2027,  3373,  1996,  9252,  8647,  1997,   102],\n",
       "         [  101,  2859,  3067,  8479,  8563,  5179,  2012,  2560,  5179, 11257,\n",
       "           2020,  2730,  1999,  1037,  5317,  3067,  3806,  7738,  1999,   102],\n",
       "         [  101,  6396,  2072,  2692,  5796, 22324,  4380,  1001,  4464,  1025,\n",
       "           1055,  9598,  3062,  2006, 14316,  5142,  2008,  6996,  3667,   102],\n",
       "         [  101, 13420,  1005,  1055,  6034,  2191,  7840,  4606,  1010, 14492,\n",
       "          12386,  2070, 10882, 13213,  1010,  7243, 15794,  4066,  1997,   102],\n",
       "         [  101,  6904, 12229,  1005,  1055,  3263,  2705,  3442,  2707,  2003,\n",
       "           1037,  2663, 12049,  6904, 12229,  9370,  2322,  7921,  5235,   102],\n",
       "         [  101,  2634,  2071,  5136,  4501,  1005,  1055, 13329, 10340,  2047,\n",
       "           6768,  1006, 26665,  1007,  1011,  2634,  2071,  5136,  9889,   102]]),\n",
       " 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(train_loader))\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e5047728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs shape: torch.Size([32, 20])\n",
      "Labels shape: torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "print(\"Input IDs shape:\", batch['input_ids'].shape)\n",
    "print(\"Labels shape:\", batch['label'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1ccddc",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c420a8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, RNN_type, vocab_size, embedding_dim, hidden_size, num_layers, bidirectional, num_classes):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.rnn = RNN_type(input_size=embedding_dim,\n",
    "                            hidden_size=hidden_size,\n",
    "                            num_layers=num_layers,\n",
    "                            bidirectional=bidirectional,\n",
    "                            batch_first=True)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_size * (2 if bidirectional else 1), num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)  # [batch, seq_len, embed_dim]\n",
    "        outputs, _ = self.rnn(x)  # [batch, seq_len, hidden*directions]\n",
    "        outputs = outputs.mean(dim=1)  \n",
    "        y = self.fc(outputs)  # [batch, num_classes]\n",
    "        return y\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
